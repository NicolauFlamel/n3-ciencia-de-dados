# Projeto de PrevisÃ£o de SÃ©ries Temporais - Grupo 2
## PrevisÃ£o de VisualizaÃ§Ãµes de PÃ¡ginas da Wikipedia

---

## ğŸ“‹ VisÃ£o Geral

Este projeto implementa uma soluÃ§Ã£o completa de previsÃ£o de sÃ©ries temporais para prever o nÃºmero de visualizaÃ§Ãµes futuras de pÃ¡ginas da Wikipedia. O projeto estÃ¡ dividido em 5 notebooks modulares que cobrem todas as etapas do processo de Data Science.

### Desafio
Prever o nÃºmero de visualizaÃ§Ãµes futuras considerando tendÃªncias e eventos especiais, utilizando dados histÃ³ricos de trÃ¡fego web.

### Dataset
- **Fonte**: Web Traffic Time Series Forecasting (Kaggle) - Sample de 9 linhas
- **PerÃ­odo**: Julho 2015 - Dezembro 2016
- **FrequÃªncia**: DiÃ¡ria
- **Formato**: SÃ©ries temporais de visualizaÃ§Ãµes por pÃ¡gina

---

## ğŸ“š Estrutura do Projeto

O projeto estÃ¡ organizado em 5 notebooks independentes e modulares:

### 1ï¸âƒ£ **01_exploracao_dados.ipynb** (Etapa 1 - 20%)
**Coleta e ExploraÃ§Ã£o de Dados**

ConteÃºdo:
- Carregamento e documentaÃ§Ã£o do dataset
- AnÃ¡lise exploratÃ³ria completa (EDA)
- EstatÃ­sticas descritivas
- IdentificaÃ§Ã£o de valores ausentes e outliers
- AnÃ¡lise de tendÃªncias e sazonalidade
- DecomposiÃ§Ã£o de sÃ©ries temporais
- AnÃ¡lise de autocorrelaÃ§Ã£o (ACF/PACF)
- VisualizaÃ§Ãµes interativas

Outputs:
- `dados_explorados.csv`: Dataset transformado para formato long

---

### 2ï¸âƒ£ **02_preparacao_dados.ipynb** (Etapa 2 - 20%)
**PreparaÃ§Ã£o e Tratamento dos Dados**

ConteÃºdo:
- **Limpeza de Dados**:
  - ImputaÃ§Ã£o de valores ausentes (interpolaÃ§Ã£o, forward fill, mediana)
  - Tratamento de outliers (WinsorizaÃ§Ã£o)
  - RemoÃ§Ã£o de inconsistÃªncias

- **Engenharia de Features**:
  - Features temporais (dia da semana, mÃªs, trimestre)
  - Features cÃ­clicas (seno/cosseno)
  - Features de lag (1, 7, 14, 30 dias)
  - Rolling window statistics (mÃ©dia, std, min, max)
  - Features de diferenciaÃ§Ã£o

- **NormalizaÃ§Ã£o**:
  - StandardScaler (Z-score)
  - MinMaxScaler (0-1)

- **DivisÃ£o dos Dados**:
  - Train: 60%
  - Validation: 20%
  - Test: 20%
  - Respeitando ordem temporal

Outputs:
- `dados_limpos.csv`: Dataset com features
- `dados_padronizados.csv`: Dados com StandardScaler
- `dados_normalizados.csv`: Dados com MinMaxScaler
- `train_data.csv`, `val_data.csv`, `test_data.csv`: Conjuntos separados
- `metadata.json`: Metadados da preparaÃ§Ã£o

---

### 3ï¸âƒ£ **03_modelos_baseline_estatisticos.ipynb** (Etapa 3 Parte 1 - 15%)
**Modelos Baseline e EstatÃ­sticos**

ConteÃºdo:
- **Modelos Baseline**:
  - Naive (PersistÃªncia)
  - MÃ©dia MÃ³vel Simples (janelas de 7, 14, 30 dias)
  - SuavizaÃ§Ã£o Exponencial Simples (SES)

- **Modelos EstatÃ­sticos**:
  - ARIMA (com auto_arima para otimizaÃ§Ã£o)
  - SARIMA (sazonalidade semanal)
  - Holt-Winters (Triple Exponential Smoothing)

- **MÃ©tricas de AvaliaÃ§Ã£o**:
  - MAE (Mean Absolute Error)
  - RMSE (Root Mean Squared Error)
  - MAPE (Mean Absolute Percentage Error)
  - RÂ² (Coeficiente de DeterminaÃ§Ã£o)

Outputs:
- `baseline_statistical_comparison.csv`: ComparaÃ§Ã£o dos modelos
- `baseline_statistical_results.pkl`: Resultados detalhados

---

### 4ï¸âƒ£ **04_modelos_machine_learning.ipynb** (Etapa 3 Parte 2 - 15%)
**Modelos de Machine Learning**

ConteÃºdo:
- **Prophet (Facebook)**:
  - DetecÃ§Ã£o automÃ¡tica de tendÃªncias
  - MÃºltiplas sazonalidades
  - Robusto a outliers e dados ausentes

- **RegressÃ£o com Features Temporais**:
  - Ridge Regression
  - Random Forest
  - Gradient Boosting
  - XGBoost
  - Feature importance analysis

- **Deep Learning**:
  - LSTM (Long Short-Term Memory)
  - Arquitetura com dropout
  - Early stopping
  - PrevisÃµes iterativas

Outputs:
- `all_models_comparison.csv`: ComparaÃ§Ã£o de todos os modelos
- `all_results.pkl`: Resultados completos
- `best_model.json`: InformaÃ§Ãµes do melhor modelo

---

### 5ï¸âƒ£ **05_avaliacao_final.ipynb** (Etapa 4 - 20%)
**AvaliaÃ§Ã£o e ComparaÃ§Ã£o de Modelos**

ConteÃºdo:
- **AnÃ¡lise Comparativa**:
  - Tabela comparativa completa
  - Rankings por mÃ©trica
  - Heatmaps de performance

- **AnÃ¡lise de ResÃ­duos**:
  - Teste de normalidade (Shapiro-Wilk)
  - Teste de autocorrelaÃ§Ã£o (Ljung-Box)
  - Q-Q plots
  - ACF dos resÃ­duos

- **ValidaÃ§Ã£o Cruzada Temporal**:
  - Expanding Window
  - AvaliaÃ§Ã£o de estabilidade

- **SeleÃ§Ã£o do Modelo Final**:
  - Justificativa detalhada
  - Pontos fortes e limitaÃ§Ãµes
  - RecomendaÃ§Ãµes para produÃ§Ã£o

- **Dashboard Executivo**:
  - VisualizaÃ§Ãµes consolidadas
  - SumÃ¡rio de resultados

Outputs:
- `relatorio_final.txt`: RelatÃ³rio completo do projeto

---

## ğŸš€ Como Executar

### PrÃ©-requisitos
```bash
# Python 3.9+
# Jupyter Notebook ou JupyterLab
```

### InstalaÃ§Ã£o de DependÃªncias

As dependÃªncias sÃ£o instaladas automaticamente em cada notebook, mas vocÃª pode instalÃ¡-las manualmente:

```bash
pip install pandas numpy matplotlib seaborn plotly
pip install statsmodels pmdarima prophet
pip install scikit-learn xgboost
pip install tensorflow keras
```

### Ordem de ExecuÃ§Ã£o

Execute os notebooks na ordem numÃ©rica:

1. **01_exploracao_dados.ipynb**
   - Carregue o arquivo `train_1_sample.csv`
   - Execute todas as cÃ©lulas

2. **02_preparacao_dados.ipynb**
   - Usa output do notebook anterior
   - Execute todas as cÃ©lulas

3. **03_modelos_baseline_estatisticos.ipynb**
   - Usa outputs do notebook 2
   - Execute todas as cÃ©lulas

4. **04_modelos_machine_learning.ipynb**
   - Usa outputs dos notebooks anteriores
   - Execute todas as cÃ©lulas
   - âš ï¸ LSTM pode demorar alguns minutos

5. **05_avaliacao_final.ipynb**
   - Consolida todos os resultados
   - Execute todas as cÃ©lulas
   - Gera relatÃ³rio final

---

## ğŸ“Š Modelos Implementados

### Baseline (3 modelos)
- âœ… Naive (PersistÃªncia)
- âœ… MÃ©dia MÃ³vel Simples
- âœ… SuavizaÃ§Ã£o Exponencial Simples

### EstatÃ­sticos (3 modelos)
- âœ… ARIMA
- âœ… SARIMA
- âœ… Holt-Winters

### Machine Learning (6 modelos)
- âœ… Prophet
- âœ… Ridge Regression
- âœ… Random Forest
- âœ… Gradient Boosting
- âœ… XGBoost
- âœ… LSTM (Deep Learning)

**Total: 12 modelos**

---

## ğŸ“ˆ MÃ©tricas de AvaliaÃ§Ã£o

Todos os modelos sÃ£o avaliados usando 4 mÃ©tricas principais:

1. **MAE** (Mean Absolute Error)
   - Erro mÃ©dio absoluto
   - Mesma unidade que a variÃ¡vel alvo
   - InterpretaÃ§Ã£o direta

2. **RMSE** (Root Mean Squared Error)
   - Penaliza erros grandes
   - SensÃ­vel a outliers

3. **MAPE** (Mean Absolute Percentage Error)
   - Erro percentual mÃ©dio
   - Independente de escala
   - FÃ¡cil interpretaÃ§Ã£o

4. **RÂ²** (Coeficiente de DeterminaÃ§Ã£o)
   - ProporÃ§Ã£o de variÃ¢ncia explicada
   - Varia de 0 a 1 (maior = melhor)

---

## ğŸ¯ Resultados Esperados

ApÃ³s executar todos os notebooks, vocÃª terÃ¡:

### Arquivos Gerados
```
/
â”œâ”€â”€ dados_explorados.csv
â”œâ”€â”€ dados_limpos.csv
â”œâ”€â”€ dados_padronizados.csv
â”œâ”€â”€ dados_normalizados.csv
â”œâ”€â”€ train_data.csv
â”œâ”€â”€ val_data.csv
â”œâ”€â”€ test_data.csv
â”œâ”€â”€ metadata.json
â”œâ”€â”€ baseline_statistical_comparison.csv
â”œâ”€â”€ baseline_statistical_results.pkl
â”œâ”€â”€ all_models_comparison.csv
â”œâ”€â”€ all_results.pkl
â”œâ”€â”€ best_model.json
â””â”€â”€ relatorio_final.txt
```

### Insights
- IdentificaÃ§Ã£o do melhor modelo
- ComparaÃ§Ã£o detalhada de performance
- AnÃ¡lise de resÃ­duos
- RecomendaÃ§Ãµes para produÃ§Ã£o

---

## ğŸ” Principais Insights do Projeto

### 1. Sazonalidade
- PadrÃ£o semanal identificado nas visualizaÃ§Ãµes
- VariaÃ§Ã£o entre dias Ãºteis e fins de semana

### 2. TendÃªncias
- TendÃªncias de longo prazo capturadas
- MudanÃ§as de comportamento ao longo do tempo

### 3. Features Importantes
- Lags de 7, 14 e 30 dias
- MÃ©dias mÃ³veis
- Features cÃ­clicas (dia da semana, mÃªs)

### 4. Performance dos Modelos
- Modelos de ML geralmente superam baseline
- LSTM e XGBoost tendem a ter boa performance
- Prophet Ã© robusto e fÃ¡cil de usar

---

## ğŸ“‹ Checklist de Qualidade

### AnÃ¡lise ExploratÃ³ria âœ…
- [x] EstatÃ­sticas descritivas completas
- [x] VisualizaÃ§Ãµes de tendÃªncias
- [x] IdentificaÃ§Ã£o de sazonalidade
- [x] AnÃ¡lise de autocorrelaÃ§Ã£o
- [x] DetecÃ§Ã£o de outliers

### PreparaÃ§Ã£o de Dados âœ…
- [x] Tratamento de valores ausentes
- [x] Tratamento de outliers
- [x] Engenharia de features
- [x] NormalizaÃ§Ã£o/PadronizaÃ§Ã£o
- [x] DivisÃ£o temporal correta

### Modelagem âœ…
- [x] Modelos baseline implementados
- [x] Modelos estatÃ­sticos (ARIMA, SARIMA, HW)
- [x] Modelos de ML (Prophet, XGBoost, RF, etc)
- [x] Deep Learning (LSTM)
- [x] OtimizaÃ§Ã£o de hiperparÃ¢metros

### AvaliaÃ§Ã£o âœ…
- [x] MÃºltiplas mÃ©tricas calculadas
- [x] ComparaÃ§Ã£o visual de modelos
- [x] AnÃ¡lise de resÃ­duos
- [x] ValidaÃ§Ã£o cruzada temporal
- [x] SeleÃ§Ã£o e justificativa do melhor modelo

---

## ğŸ“š ReferÃªncias

### DocumentaÃ§Ã£o
- [Statsmodels](https://www.statsmodels.org/)
- [Prophet](https://facebook.github.io/prophet/)
- [XGBoost](https://xgboost.readthedocs.io/)
- [TensorFlow/Keras](https://www.tensorflow.org/)

### Datasets
- [Kaggle: Web Traffic Time Series Forecasting](https://www.kaggle.com/c/web-traffic-time-series-forecasting)

### Papers

- Box, G. E., & Jenkins, G. M. (1976). Time series analysis: forecasting and control
- Taylor, S. J., & Letham, B. (2018). Forecasting at scale (Prophet paper)
- Hochreiter, S., & Schmidhuber, J. (1997). Long short-term memory (LSTM paper)
